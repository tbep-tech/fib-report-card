---
title: "Brainstorming/Scratch Pad"
format: html
---

This file is where I'll be "thinking out loud" and working out what to make the functions and products look like. It may not be pretty. The process never is.   

```{r}
library(tidyverse)
library(sf)
library(mapview)
```



# don't run this when testing precip/fib fun - go straight to that section  

I copied Marcus's code down there that identifies stations, pixels etc.  


```{r}
dbasins <- read_sf(here::here("data", "geospatial", "dbasins-galb.shp"))
# mapview(dbasins)
```

```{r}
catchments <- read_sf(here::here("data", "geospatial", "TB_Select_Fib_Catchments_Dissolved.shp"))
# mapview(catchments)
```

```{r}
swfwmd_pixels <- read_sf(here::here("data", "geospatial", "swfwmd_pixel_2_utm_m_83.shp"))
```

# Precip stuff that's mostly superceded by read_importrain() fn  

## define pixels over which to average  

Function for defining precip pixels for each station/catchment needs to:  

1.  Read in catchments file - specify layer as argument  
2.  Read in SWFWMD pixels file - can be specified, but should have default because this shouldn't change  
3.  Get them into the same CRS  
4.  Intersect them  
5.  Return a data frame or list of pixels in each catchment and which stations they go with    


Then that data frame or list or whatever will go into another function to get the precip records and average to catchment level over certain time frames.

```{r}
define_station_pixels <- function(catchment_layer,
                                    pixels_layer) {
    catch2 <- st_transform(catchment_layer,
                           crs = st_crs(pixels_layer))
    catch_pixels <- st_intersection(pixels_layer, catch2)
    # station_pixels <- catch_pixels |> 
    #     st_drop_geometry() |> 
    #     group_by(StationNam) |> 
    #     summarize(pixels = paste(unique(PIXEL), collapse = ", ")) |> 
    #     ungroup()
    
    station_pixels <- catch_pixels |> 
        st_drop_geometry() |> 
        select(StationNam, PIXEL)
    
    station_pixels
}
```

```{r}
stn_pix <- define_station_pixels(catchments, swfwmd_pixels) |> 
    nest(.by = StationNam,
         .key = "pixels")
```

That's not working the way I want it to. I want to be able to say something like "use the pixels %in% the row related to these stations".  Could split the data frame and return it as a list? With a single data frame per station? That doesn't feel right either.  Maybe it depends some on what the next function is going to look like - how to use this output to generate those catchment-wide averages.  

  
## calculate average precip across a catchment  

```{r}
# read in precip data - this was created during the fibs_and_hydrology part of the project
prcp_daily <- readRDS(here::here("data", "precipitation", "compiledDailyRainfall.rds"))

prcp_daily_plus_lag <- prcp_daily |> 
    arrange(PIXEL, date) |> 
    group_by(PIXEL) |> 
    mutate(prev24 = inches + lag(inches, 1),
           prev48 = prev24 + lag(inches, 2),
           prev72 = prev48 + lag(inches, 3)) |> 
    ungroup()

```


here, we need to define:  

1.  what are the catchments/stations to deal with  
2.  which pixels are we using for each catchment/station (use output from function above)  
3.  where is the data frame with precip by date/pixel combination  
4.  for each pixel, generate - that day; 24 hrs; 48 hrs; 72 hrs before  
5.  for each catchment/station, group and average precip amounts  

**NEED TO MAKE THE COLUMN NAMES FLEXIBLE**  - they're hard-coded as StationNam and PIXEL in the body of the function because I was having problems  

**ALSO NEED TO** calculate lags by pixel and average those  

```{r}
calc_station_precip <- function(precip_data,
                                station_df,
                                station_names = "StationNam",
                                pixel_ids = "PIXEL"
                                ){
    # station data is the data frame that defines which pixels are associated with each given station  
    # station_names is the name of the column with station names - needs to be quoted
    # pixel_ids is the column with all the pixels - needs to be quoted
    # precip data is the daily precip by pixel downloaded from swfwmd
    
    
    stns <- unlist(unique(station_df[ , station_names]))
    stn_prcp <- list()
    for(i in seq_along(stns)){
        pixs <- station_df[station_df$StationNam == stns[i], "PIXEL"]
        # pixs <- station_df |> 
        #     filter({{station_names}} == stns[i]) |> 
        #     select({{pixel_ids}})
        prcp <- precip_data[precip_data$PIXEL %in% pixs$PIXEL, ]
        prcp_avgd <- prcp |> 
            group_by(date) |> 
            summarize(inches = mean(inches, na.rm = TRUE))
        stn_prcp[[i]] <- prcp_avgd
    }
    names(stn_prcp) <- stns
    stn_prcp
}
```

```{r}
stn_prcps <- calc_station_precip(prcp_daily, stn_pix)
```


# Link precip to entero  

Assume that Marcus's 'raindl' function worked. For now I'll just read in the rainfall data I've got and modify it, but give it the same names as the function output: station, date, rain. Need to write a function that takes as input:  

-  entero sample data frame  
-  precip by station/date data frame  
-  temporal window (day of sampling? 48 hrs? 72 hrs?)  
-  threshold for defining 'wet' sample over that temporal window (e.g. 1 in)  

....and returns a data frame that is the entero sample df, but with an additional column identifying each sample as 'wet' or 'dry'. Maybe with some attributes saying what the temporal window and threshold were?? Should the precip amounts be included too? Personally I like to have all the info, but that would bloat the data frame.... hm, could return a list or something, like model objects return, so you have access to all the pieces and parts if you want them?  

## read in some stuff  

code copied from `raindl.R`; thanks Marcus  

only change needed is FLCOSP_WQX-CENTRAL * should be CENTRAL CANAL; I do this below  

```{r}
# station, catchment data
catchments <- read_sf(here::here("data", "geospatial", "TB_Select_Fib_Catchments_Dissolved.shp"))

# catchment pixels, final includes full station names in long format
# this will need to be saved to tbeptools
pixels <- read_sf(here::here("data", "geospatial", "swfwmd_pixel_2_utm_m_83.shp"))
catch2 <- st_transform(catchments,
                       crs = st_crs(pixels))
catch_pixels <- st_intersection(pixels, catch2) |> 
    sf::st_drop_geometry() |> 
    select(PIXEL, StationNam) |> 
    separate_wider_delim(StationNam, delim = " + ", names = c('a','b', 'c','d'), 
                         too_few = 'align_start', cols_remove = F) |> 
    pivot_longer(cols = c(a, b, c, d), names_to = 'col', values_to = 'value') |> 
    filter(!is.na(value)) |> 
    mutate(
        station = case_when(
            StationNam == '21FLHILL_WQX-102 + 103 + 619' & col != 'a' ~ paste0('21FLHILL_WQX-', value),
            StationNam == '21FLHILL_WQX-596 + 597' & col != 'a' ~ paste0('21FLHILL_WQX-', value),
            StationNam == '21FLHILL_WQX-136 + 264' & col != 'a' ~ paste0('21FLHILL_WQX-', value),
            StationNam == '21FLHILL_WQX-112 + 180' & col != 'a' ~ paste0('21FLHILL_WQX-', value),
            StationNam == '21FLDOH_WQX-MANATEE152 + 153' & col != 'a' ~ paste0('21FLDOH_WQX-', value),
            StationNam == '21FLCOSP_WQX-NORTH CANAL + SOUTH CANAL + CENTRAL *' & col != 'a' ~ paste0('21FLCOSP_WQX-', value),
            StationNam == '21FLPDEM_WQX-39-01 + 39-05' & col != 'a' ~ paste0('21FLPDEM_WQX-', value),
            StationNam == '21FLMANA_WQX-LM3 + LM4 + LM5 + LM6' & col != 'a' ~ paste0('21FLMANA_WQX-', value),
            T ~ value
        )
    ) |> 
    select(station, pixel = PIXEL)
```

```{r}
catch_pixels <- catch_pixels |> 
    mutate(station = case_when(station == "21FLCOSP_WQX-CENTRAL *" ~ "21FLCOSP_WQX-CENTRAL CANAL",
                               .default = station))
```



## set up data frames  

### FIB  

At this point still using `dataRetrieval` function; need to modify `tbeptools` function but output should generally look like this (right??)  


pull data using stations identified in `catch_pixels` data frame. This is modified code from `R/exploring_dataRetrieval.qmd`.    

```{r}
library(dataRetrieval)
```

```{r}
# set up the query
# can enter start dates here if desired
# (into the args list)
stations <- unique(catch_pixels$station)
entero_names <- c("Enterococci",
                  "Enterococcus")
startDate <- as.Date("2020-01-01")
endDate <- as.Date("2023-12-31")
# startDateHi would be an end date

args <- list(
    siteid = stations,
    characteristicName = entero_names,
    startDateLo = startDate,
    startDateHi = endDate
)
```

```{r}
# see what we'll get
wqp_summ <- readWQPdata(args, querySummary = TRUE)

(n_results <- wqp_summ$`total-result-count`)
(n_sites <- wqp_summ$`total-site-count`)
```

```{r}
# do the download
wqp_dat <- readWQPdata(args, querySummary = FALSE)
```

```{r}
# pull only columns of interest
# remove any samples where the result was "Not Reported", then make it numeric
fib_dat <- wqp_dat |> 
    select(station = MonitoringLocationIdentifier,
           FIBconc = ResultMeasureValue, # - the result (has characters in here too - "Not Reported")  
           FIBunits = ResultMeasure.MeasureUnitCode,  
           date = ActivityStartDate,
           time = ActivityStartTime.Time, # local time  
           time_zone = ActivityStartTime.TimeZoneCode,
           MDL = DetectionQuantitationLimitMeasure.MeasureValue,
           LabComments = ResultLaboratoryCommentText) |> 
    filter(FIBconc != "Not Reported") |> 
    mutate(FIBconc = as.numeric(FIBconc),
           FIBcensored = case_when(FIBconc <= MDL ~ TRUE,
                                   .default = FALSE)) |> 
    relocate(date, station, FIBconc) |> 
    relocate(FIBcensored, .after = FIBconc) |> 
    arrange(station, date)
```


### precip data  

```{r}
# read in precip data - this was created during the fibs_and_hydrology part of the project
prcp_daily <- readRDS(here::here("data", "precipitation", "compiledDailyRainfall.rds")) |> 
    set_names(c("pixel", "date", "rain"))

# prcp_daily_plus_lag <- prcp_daily |> 
#     arrange(PIXEL, date) |> 
#     group_by(PIXEL) |> 
#     mutate(prev24 = inches + lag(inches, 1),
#            prev48 = prev24 + lag(inches, 2),
#            prev72 = prev48 + lag(inches, 3)) |> 
#     ungroup()
```

```{r}
prcp_stn <- dplyr::left_join(catch_pixels, prcp_daily, by = 'pixel', relationship = 'many-to-many') |> 
            dplyr::summarise(
                rain = mean(rain, na.rm = T),
                .by = c(station, date)
            )
```

## Test the rain function again  

having sourced raindl.R

```{r}
source(here::here("R", "raindl.R"))
```

```{r}
rain2021 <- read_importrain(curyr = 2021, catch_pixels = catch_pixels)
```


## set up function  

```{r}
#' Identify Fecal Indicator Bacteria samples as coming from a 'wet' or 'dry' time period  
#'
#' @param fibdata input data frame
#' @param precipdata input data frame as returned by \code{\link{read_importrain}}. columns should be: station, date (yyyy-mm-dd), rain (in inches).  
#' @param temporal_window numeric, number of days precipitation should be summed over (1 = day of sample only; 2 = day of sample + day before; etc.)
#' @param wet_threshold  numeric, inches accumulated through the defined temporal window, above which a sample should be defined as being from a 'wet' time period
#'
#' @return
#' 
#' @details
#' 
#' @export
#'
#' @examples
anlz_fibwetdry <- function(fibdata,
                           precipdata,
                           temporal_window = 1,
                           wet_threshold = 0.5){
    
    # in precipdata, calculate precip in the temporal window
    
    # want all the lags up to [temporal_window - 1]  (e.g. for 2-day temporal window, want rain + lag1(rain); for 3-day window want rain + lag1 + lag2),
    # so build the formula for that. if temporal window = 1, just use "rain" as the formula.
    
    if(temporal_window > 1){
        lag_formula = ""
        for(i in 2:temporal_window){
            lag_formula <- paste0(lag_formula, "+ lag(rain, ", i-1, ")")
        }
        formula_string = paste("rain", lag_formula)
    } else {
        formula_string = "rain"
    }
    
    formula_obj = parse(text = formula_string)
    
    
    # now calculate
    prcp_calcd <- precipdata |> 
        group_by(station) |> 
        mutate(rain_total = eval(formula_obj)) |> 
        rename(rain_sampleDay = rain) |> 
        ungroup()
    
    
    # left join, fibdata = left, prcipdata = right; on station and date
    # use threshold to show wet or dry
    out <- left_join(fibdata, prcp_calcd,
                     by = c("station", "date")) |> 
        mutate(wet_sample = rain_total >= wet_threshold)
    
    return(out)
}
```

```{r}
test <- anlz_fibwetdry(fib_dat, prcp_stn)

test2 <- anlz_fibwetdry(fib_dat, prcp_stn, temporal_window = 2)

test4 <- anlz_fibwetdry(fib_dat, prcp_stn, temporal_window = 4)
```

